{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Plan Recommender Model\n",
    "\n",
    "\n",
    "In this assignment, we want to evaluate your ability to engineer features and design and evaluate a model. We will create a multi-class classification model to recommend medical plans to employees based on user data (inputs) and medical plan labels (outputs). We have access to data from ~250 users. Each user is classified into 1 of 3 plans by actuaries. \n",
    "\n",
    "Feel free to use any python packages you would like. You are also allowed to google for help with method names / syntax! \n",
    "\n",
    "Dataset Columns:\n",
    "\n",
    "- **age**: age of employee\n",
    "- **family**: who is covered? (Just Me, Me and my Spouse', Me and my kids, Me, Spouse, and Kids)\n",
    "- **salary**: income of employee\n",
    "- **household_salaries**: household income of employee\n",
    "- **financial_risk_preference**: (1) Prefer Savings to Prefer Protection (5) \n",
    "- **preexisting_conditions**: conditions that require frequent doctor visits (cancer, high blood pressure, etc)\n",
    "- **prescription_costs**: costs of annual prescription \n",
    "- **pcp_costs**: costs of primary care costs last year\n",
    "- **specialist_costs**: annual cost of speciality care costs last year\n",
    "- **pcp_visits**: number of pcp visits last year\n",
    "- **qle**: qualifying life event that might incur costs (baby, medical procedure, married, moving)\n",
    "- **specialty_visits**: number of specalist visits last year \n",
    "- **exercises**: frequency of exercise (I exercise everyday, I exercise 3x a week, I don't exercise)\n",
    "- **savings**: if they had to pay $3000, how would they pay for this? (borrow money, have savings, HSA)\n",
    "- **label**: plan recommendation as indicated by actuary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m surveys \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/surveys.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m surveys\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "surveys = pd.read_csv(\"data/surveys.csv\", index_col=0).reset_index(drop=True)\n",
    "surveys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = surveys.drop(\"label\", axis=1)\n",
    "y = surveys.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Write code to split the data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 1 - sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.75\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 2 - from scratch without stratified sampling \n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "train_size = 0.80\n",
    "\n",
    "indices = [i for i in range(len(X))]\n",
    "shuffle(indices)\n",
    "num_training_indices = int(len(indices) * train_size)\n",
    "train_indices = indices[:num_training_indices]\n",
    "test_indices = indices[num_training_indices:]\n",
    "\n",
    "# split the actual data\n",
    "X_train, X_test = X.iloc[train_indices], X.iloc[test_indices], \n",
    "y_train, y_test = y[train_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) You will train a multi-class classification model later in the script. Consider what model you would like to train, and implement a feature normalization strategy. Explain your reasoning behind your strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'salary', 'household_salaries', 'financial_risk_preference',\n",
       "       'prescription_costs', 'pcp_costs', 'specialist_costs', 'pcp_visits',\n",
       "       'specialty_visits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = X_train.select_dtypes(include='number').columns\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['family', 'preexisting_conditions', 'qle', 'exercises', 'savings'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = X_train.select_dtypes(include='object').columns\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler() ### Note if candidate selects tree-based model, normalization not required!! \n",
    "X_train_numeric = pd.DataFrame(scaler.fit_transform(X_train[numeric_features]), columns=numeric_features, index=X_train.index)\n",
    "X_test_numeric = pd.DataFrame(scaler.transform(X_test[numeric_features]), columns=numeric_features, index=X_test.index)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "X_train_categorical = pd.DataFrame(enc.fit_transform(X_train[categorical_features]).toarray(), columns=enc.get_feature_names_out(), index=X_train.index)\n",
    "X_test_categorical = pd.DataFrame(enc.transform(X_test[categorical_features]).toarray(), columns=enc.get_feature_names_out(), index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train_numeric.merge(X_train_categorical, left_index=True, right_index=True)\n",
    "X_test_normalized = X_test_numeric.merge(X_test_categorical, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Select one model and train. We do not expect you to implement hyperparameter tuning, but please talk through how you would set this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "model = clf.fit(X_train_normalized, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Evaluate Model: Display model train/test classification metrics of your choice and describe them in the context of this problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics: \n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Cigna Base HDHP       0.92      0.94      0.93        49\n",
      "   Cigna Choice HDHP       0.82      0.87      0.85       102\n",
      "Cigna Copay Plan PPO       0.81      0.72      0.76        65\n",
      "\n",
      "            accuracy                           0.84       216\n",
      "           macro avg       0.85      0.84      0.85       216\n",
      "        weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Test Metrics: \n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Cigna Base HDHP       0.91      0.83      0.87        12\n",
      "   Cigna Choice HDHP       0.76      0.93      0.84        28\n",
      "Cigna Copay Plan PPO       0.90      0.60      0.72        15\n",
      "\n",
      "            accuracy                           0.82        55\n",
      "           macro avg       0.86      0.79      0.81        55\n",
      "        weighted avg       0.83      0.82      0.81        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_train_predict = model.predict(X_train_normalized)\n",
    "print(\"Train Metrics: \")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "\n",
    "y_test_predict = model.predict(X_test_normalized)\n",
    "print(\"Test Metrics: \")\n",
    "print(classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Monitoring: Describe metrics you would consider to monitor this model in production.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('nayya_mind_agnostic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "337c7ecc8912e6298565ce95f3f08fca19887c38f0cbf663bf76f669cee670e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
